{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disturb_pc(pcData, types, levels, ROI, radar=False, lidar=False):\n",
    "    \"\"\"\n",
    "    Apply a series of disturbances to a point cloud dataset.\n",
    "\n",
    "    Parameters:\n",
    "    pcData (numpy.ndarray): The input point cloud data, typically in the shape (n, 3) or (n, 4).\n",
    "    types (list of str): List of disturbance types to apply. Options include \"add_points\", \"lose_points\", \n",
    "                         \"shifting\", \"cluster\", \"information_noise\", and \"None\".\n",
    "    levels (list of float): List of disturbance levels corresponding to each disturbance type.\n",
    "    ROI (dict): Dictionary specifying the Region of Interest (ROI) with keys \"xmin\", \"xmax\", \"ymin\", \"ymax\", \n",
    "                \"zmin\", and \"zmax\".\n",
    "    radar (bool): If True, apply radar-specific processing in relevant disturbances.\n",
    "    lidar (bool): If True, apply lidar-specific processing in relevant disturbances.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The disturbed point cloud after applying all specified disturbances.\n",
    "    \n",
    "    Raises:\n",
    "    NotImplementedError: If a disturbance type is not implemented.\n",
    "    \"\"\"\n",
    "    operations = {\n",
    "        \"add_points\": add_points,\n",
    "        \"lose_points\": lose_random_points,\n",
    "        \"shifting\": shifting,\n",
    "        \"cluster\": lambda data, level, ROI: cluster_radar(data, level, ROI) if \\\n",
    "                        radar else cluster_lidar(data, level, ROI),\n",
    "        \"information_noise\": information_noise,\n",
    "        \"None\": lambda data, level, ROI: data\n",
    "    }\n",
    "\n",
    "    for type, level in zip(types, levels):\n",
    "        if type in operations:\n",
    "            parameter = level / 4\n",
    "            pcData = operations[type](pcData, parameter, ROI)\n",
    "            pcData = filter_points_in_roi(pcData, ROI)  # Sicherstellen, dass Punkte innerhalb des ROI bleiben\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Operation '{type}' is not implemented.\")\n",
    "    \n",
    "    return pcData\n",
    "\n",
    "def information_noise(pcData, parameter, ROI):\n",
    "    \"\"\"\n",
    "    Add noise to the additional information (intensity or magnitude) of each point in the point cloud.\n",
    "\n",
    "    Parameters:\n",
    "    pcData (numpy.ndarray): The input point cloud data, typically in the shape (n, 4) or (n, 5).\n",
    "    parameter (float): The disturbance parameter affecting the noise level.\n",
    "    ROI (dict): Dictionary specifying the Region of Interest (ROI) with keys \"xmin\", \"xmax\", \"ymin\", \"ymax\", \n",
    "                \"zmin\", and \"zmax\".\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The point cloud with noisy additional information.\n",
    "    \"\"\"\n",
    "    rand_range = 100 if pcData.shape[1] == 4 else 70\n",
    "    rand_i = np.random.uniform(-rand_range * parameter, rand_range * parameter, pcData.shape[0])\n",
    "    pcData[:, 3] += rand_i\n",
    "    \n",
    "    if pcData.shape[1] > 4:\n",
    "        rand_v = np.random.uniform(-5 * parameter, 5 * parameter, pcData.shape[0])\n",
    "        pcData[:, 4] += rand_v\n",
    "    \n",
    "    return pcData\n",
    "\n",
    "def add_points(pcData, parameter, ROI):\n",
    "    \"\"\"\n",
    "    Add random points to the point cloud within the specified Region of Interest (ROI).\n",
    "\n",
    "    Parameters:\n",
    "    pcData (numpy.ndarray): The input point cloud data, typically in the shape (n, 3) or (n, 4).\n",
    "    parameter (float): The disturbance parameter determining the number of points to add.\n",
    "    ROI (dict): Dictionary specifying the Region of Interest (ROI) with keys \"xmin\", \"xmax\", \"ymin\", \"ymax\", \n",
    "                \"zmin\", and \"zmax\".\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The point cloud with additional random points added.\n",
    "    \"\"\"\n",
    "    num_points = int(parameter * pcData.shape[0])\n",
    "    rand_x = np.random.uniform(ROI[\"xmin\"], ROI[\"xmax\"], num_points)\n",
    "    rand_y = np.random.uniform(ROI[\"ymin\"], ROI[\"ymax\"], num_points)\n",
    "    rand_z = np.random.uniform(ROI[\"zmin\"], ROI[\"zmax\"], num_points)\n",
    "    \n",
    "    if pcData.shape[1] == 4:\n",
    "        rand_i = np.random.uniform(0, 100, num_points)\n",
    "        rand_points = np.column_stack([rand_x, rand_y, rand_z, rand_i])\n",
    "    else:\n",
    "        rand_m = np.random.uniform(0, 70, num_points)\n",
    "        rand_v = np.random.uniform(-5, 5, num_points)\n",
    "        rand_points = np.column_stack([rand_x, rand_y, rand_z, rand_m, rand_v])\n",
    "    \n",
    "    return np.concatenate((pcData, rand_points), axis=0)\n",
    "\n",
    "def shifting(pcData, parameter, ROI):\n",
    "    \"\"\"\n",
    "    Apply random shifts to all points in the point cloud based on a random shift factor.\n",
    "\n",
    "    Parameters:\n",
    "    pcData (numpy.ndarray): The input point cloud data, typically in the shape (n, 3).\n",
    "    parameter (float): The disturbance parameter determining the magnitude of the shift.\n",
    "    ROI (dict): Dictionary specifying the Region of Interest (ROI) with keys \"xmin\", \"xmax\", \"ymin\", \"ymax\", \n",
    "                \"zmin\", and \"zmax\".\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The shifted point cloud.\n",
    "    \"\"\"\n",
    "    rand_shift_factor = np.random.uniform(-2 * parameter, 2 * parameter, pcData.shape[0])\n",
    "    norm_factors = np.linalg.norm(pcData[:, 0:3], axis=1).reshape(-1, 1)\n",
    "    pcData[:, 0:3] += pcData[:, 0:3] * (rand_shift_factor / norm_factors)\n",
    "    return pcData\n",
    "\n",
    "def cluster_lidar(pcData, parameter, ROI):\n",
    "    \"\"\"\n",
    "    Add clusters of points to the point cloud, simulating local disturbances in the data.\n",
    "\n",
    "    Parameters:\n",
    "    pcData (numpy.ndarray): The input point cloud data, typically in the shape (n, 3) or (n, 4).\n",
    "    parameter (float): The disturbance parameter determining the size and number of clusters.\n",
    "    ROI (dict): Dictionary specifying the Region of Interest (ROI) with keys \"xmin\", \"xmax\", \"ymin\", \"ymax\", \n",
    "                \"zmin\", and \"zmax\".\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The point cloud with additional clusters of points.\n",
    "    \"\"\"\n",
    "    amount_cluster = np.random.randint(max(1, 16 * parameter**2 - 2), 16 * parameter**2 + 3) if parameter != 0 else 0\n",
    "\n",
    "    for _ in range(amount_cluster):\n",
    "        offset = np.array([np.random.uniform(ROI[\"xmin\"], ROI[\"xmax\"]),\n",
    "                           np.random.uniform(ROI[\"ymin\"], ROI[\"ymax\"]),\n",
    "                           np.random.uniform(ROI[\"zmin\"], ROI[\"zmax\"])])\n",
    "        \n",
    "        dist = np.linalg.norm(offset)\n",
    "        if dist < 7:\n",
    "            continue\n",
    "        \n",
    "        theta_length = max(1, int(round(16 - 3/10 * dist) - 3 * offset[2]))\n",
    "        phi_length = max(1, int(round(50 - dist)))\n",
    "\n",
    "        r = np.random.uniform(0.1 + parameter**2 * 2, 1 + parameter**2 * 2)\n",
    "        theta_list = np.linspace(1, np.pi - 1, num=theta_length)\n",
    "        phi_list = np.linspace(0.5, np.pi - 0.5, num=phi_length)\n",
    "\n",
    "        sphere = np.array([[r * np.sin(theta) * np.cos(phi) + np.random.uniform(-0.1, 0.1),\n",
    "                            -r * np.sin(theta) * np.sin(phi) + np.random.uniform(-0.1, 0.1),\n",
    "                            r * np.cos(theta) + np.random.uniform(-0.1, 0.1)]\n",
    "                           for theta, phi in itertools.product(theta_list, phi_list)])\n",
    "        \n",
    "        sphere = sphere[sphere[:, 2] > ROI[\"zmin\"] + 0.2]\n",
    "        \n",
    "        phi_angle = -np.arctan2(offset[0], offset[1])\n",
    "        theta_angle = -np.arcsin(offset[2] / dist)\n",
    "        sphere = rotate_points(sphere, rt_matrix(phi_angle, theta_angle))\n",
    "\n",
    "        sphere += offset\n",
    "\n",
    "        rand_i = np.random.uniform(0, 100) + np.random.normal(0, 4, (len(sphere), 1))\n",
    "        rand_cluster = np.column_stack((sphere, rand_i))\n",
    "\n",
    "        pcData = np.concatenate((pcData, rand_cluster), axis=0)\n",
    "\n",
    "    return pcData\n",
    "\n",
    "def cluster_radar(pcData, parameter, ROI):\n",
    "    \"\"\"\n",
    "    Add clusters of points to the point cloud, simulating disturbances caused by radar-specific effects.\n",
    "\n",
    "    Parameters:\n",
    "    pcData (numpy.ndarray): The input point cloud data, typically in the shape (n, 4) or (n, 5).\n",
    "    parameter (float): The disturbance parameter determining the size and number of clusters.\n",
    "    ROI (dict): Dictionary specifying the Region of Interest (ROI) with keys \"xmin\", \"xmax\", \"ymin\", \"ymax\", \n",
    "                \"zmin\", and \"zmax\".\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The point cloud with additional clusters of points.\n",
    "    \"\"\"\n",
    "\n",
    "    amount_cluster = np.random.randint(max(1, 32 * parameter**2 - 2), 32 * parameter**2 + 2)\n",
    "\n",
    "    for _ in range(int(amount_cluster)):\n",
    "        size_cluster = np.random.uniform(0.1 + parameter**2 * 2, 1 + parameter**2 * 2,2)\n",
    "        points_cluster = np.random.randint(max(1, 100 * parameter**4), 100 * parameter**4 + 20)\n",
    "\n",
    "        rand_x = np.random.uniform(0, size_cluster[0], points_cluster) + np.random.uniform(ROI[\"xmin\"], ROI[\"xmax\"])\n",
    "        rand_y = np.random.uniform(0, size_cluster[1], points_cluster) + np.random.uniform(ROI[\"ymin\"], ROI[\"ymax\"])\n",
    "        rand_z = np.random.uniform(0, 1, points_cluster) + np.random.uniform(ROI[\"zmin\"], ROI[\"zmax\"])\n",
    "\n",
    "        rand_m = np.random.uniform(0, 70, points_cluster)\n",
    "        rand_cluster = np.column_stack([rand_x, rand_y, rand_z, rand_m])\n",
    "\n",
    "        pcData = np.concatenate((pcData, rand_cluster), axis=0)\n",
    "\n",
    "    return pcData\n",
    "\n",
    "def lose_random_points(pcData, parameter, ROI):\n",
    "    \"\"\"\n",
    "    Randomly remove a portion of points from the point cloud.\n",
    "\n",
    "    Parameters:\n",
    "    pcData (numpy.ndarray): The input point cloud data, typically in the shape (n, 3) or (n, 4).\n",
    "    parameter (float): The disturbance parameter determining the proportion of points to remove.\n",
    "    ROI (dict): Dictionary specifying the Region of Interest (ROI) with keys \"xmin\", \"xmax\", \"ymin\", \"ymax\", \n",
    "                \"zmin\", and \"zmax\".\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The point cloud with a portion of the points removed.\n",
    "    \"\"\"\n",
    "    keep_indices = np.random.choice(pcData.shape[0], size=int(pcData.shape[0] * (1 - parameter)), replace=False)\n",
    "    return pcData[keep_indices]\n",
    "\n",
    "def rotate_points(points, rot_t):\n",
    "    \"\"\"\n",
    "    Rotate the points in the point cloud using a given rotation matrix.\n",
    "\n",
    "    Parameters:\n",
    "    points (numpy.ndarray): The input points, typically in the shape (n, 3).\n",
    "    rot_t (numpy.ndarray): A 3x3 rotation matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The rotated point cloud.\n",
    "    \"\"\"\n",
    "    return np.dot(points[:, 0:3], rot_t.T)\n",
    "\n",
    "def rt_matrix(yaw=0, roll=0, pitch=0):\n",
    "    \"\"\"\n",
    "    Generate a 3x3 rotation matrix from yaw, roll, and pitch angles.\n",
    "\n",
    "    Parameters:\n",
    "    yaw (float): Rotation angle around the z-axis (in radians).\n",
    "    roll (float): Rotation angle around the x-axis (in radians).\n",
    "    pitch (float): Rotation angle around the y-axis (in radians).\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    c_y, s_y = np.cos(yaw), np.sin(yaw)\n",
    "    c_r, s_r = np.cos(roll), np.sin(roll)\n",
    "    c_p, s_p = np.cos(pitch), np.sin(pitch)\n",
    "    \n",
    "    rotation_matrix = np.dot(np.dot(\n",
    "        np.array([[c_y, -s_y, 0], [s_y, c_y, 0], [0, 0, 1]]),\n",
    "        np.array([[c_p, 0, s_p], [0, 1, 0], [-s_p, 0, c_p]])\n",
    "    ), np.array([[1, 0, 0], [0, c_r, -s_r], [0, s_r, c_r]]))\n",
    "    \n",
    "    return rotation_matrix\n",
    "\n",
    "def filter_points_in_roi(pcData, ROI):\n",
    "    \"\"\"\n",
    "    Filter the points in the point cloud to retain only those within a specified Region of Interest (ROI).\n",
    "\n",
    "    Parameters:\n",
    "    pcData (numpy.ndarray): The input point cloud data, typically in the shape (n, 3).\n",
    "    ROI (dict): Dictionary specifying the Region of Interest (ROI) with keys \"xmin\", \"xmax\", \"ymin\", \"ymax\", \n",
    "                \"zmin\", and \"zmax\".\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The point cloud with only the points inside the ROI.\n",
    "    \"\"\"\n",
    "    mask = (\n",
    "        (pcData[:, 0] >= ROI[\"xmin\"]) & (pcData[:, 0] <= ROI[\"xmax\"]) & \n",
    "        (pcData[:, 1] >= ROI[\"ymin\"]) & (pcData[:, 1] <= ROI[\"ymax\"]) & \n",
    "        (pcData[:, 2] >= ROI[\"zmin\"]) & (pcData[:, 2] <= ROI[\"zmax\"])\n",
    "    )\n",
    "    \n",
    "    return pcData[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class calib_astyx():\n",
    "    \"\"\"Calibration class\"\"\"\n",
    "    def __init__(self, file):\n",
    "        with open(file) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            \n",
    "        self.radar2ref = np.array(data[\"sensors\"][0][\"calib_data\"][\"T_to_ref_COS\"])\n",
    "        self.lidar2ref_cos = np.array(data[\"sensors\"][1][\"calib_data\"][\"T_to_ref_COS\"])\n",
    "        self.camera2ref = np.array(data[\"sensors\"][2][\"calib_data\"][\"T_to_ref_COS\"])\n",
    "        self.K = np.array(data[\"sensors\"][2][\"calib_data\"][\"K\"])\n",
    "        \n",
    "        self.ref2radar = self.inv_trans(self.radar2ref)\n",
    "        self.ref2lidar = self.inv_trans(self.lidar2ref_cos)\n",
    "        self.ref2camera = self.inv_trans(self.camera2ref)\n",
    "        self.K = np.array(data[\"sensors\"][2][\"calib_data\"][\"K\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def inv_trans(T):\n",
    "        rotation = np.linalg.inv(T[0:3, 0:3])\n",
    "        translation = T[0:3, 3]\n",
    "        translation = -1 * np.dot(rotation, translation.T)\n",
    "        translation = np.reshape(translation, (3, 1))\n",
    "        Q = np.hstack((rotation, translation))\n",
    "\n",
    "        return Q\n",
    "    \n",
    "    def lidar2ref(self, points):\n",
    "        n = points.shape[0]\n",
    "        \n",
    "        points_hom = np.hstack((points, np.ones((n,1))))\n",
    "        points_ref = np.dot(points_hom, np.transpose(self.lidar2ref_cos))\n",
    "        \n",
    "        return points_ref[:,0:3]\n",
    "\n",
    "    def ref2Camera(self, points, img_size):\n",
    "        obj_image = np.dot(self.ref2camera[0:3, 0:3], points.T)\n",
    "        T = self.ref2camera[0:3, 3]\n",
    "        obj_image = obj_image + T[:, np.newaxis]\n",
    "        obj_image = np.dot(self.K, obj_image)\n",
    "        obj_image = obj_image / obj_image[2]\n",
    "        obj_image = np.delete(obj_image, 2, 0)\n",
    "        mask = (obj_image[0,:] <= img_size[0]) & \\\n",
    "                (obj_image[1,:] <= img_size[1]) & \\\n",
    "                (obj_image[0,:] >= 0) & (obj_image[1,:] >= 0) & \\\n",
    "                (points[:,0] >= 0)\n",
    "        return obj_image[:, mask], mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = {\"xmin\":0,\n",
    "       \"xmax\":50,\n",
    "       \"ymin\":-25,\n",
    "       \"ymax\":25,\n",
    "       \"zmin\":-2,\n",
    "       \"zmax\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 21 \n",
    "root = \"your/path/to/dataset_astyx_hires2019\"\n",
    "img = cv2.imread(f\"{root}/camera_front/{idx:06d}.jpg\")\n",
    "lidar = filter_points_in_roi(np.loadtxt(f\"{root}/lidar_vlp16/{idx:06d}.txt\", skiprows=1), ROI)\n",
    "radar = filter_points_in_roi(np.loadtxt(f\"{root}/radar_6455/{idx:06d}.txt\", skiprows=2), ROI)\n",
    "calib = calib_astyx(f\"{root}/calibration/{idx:06d}.json\")\n",
    "lidar[:,0:3] = calib.lidar2ref(lidar[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Scatter3d(x = lidar[:,0],\n",
    "                     y = lidar[:,1],\n",
    "                     z = lidar[:,2],\n",
    "                    mode='markers', type='scatter3d',\n",
    "                    marker={\n",
    "                        'size': 1,\n",
    "                        'color': lidar[:,3],\n",
    "                        'colorscale':'rainbow',\n",
    "                        'colorbar':{\"thickness\":20}\n",
    "})]\n",
    "layout = go.Layout(\n",
    "    scene={\n",
    "        'xaxis': {'range': [0, 50], 'rangemode': 'tozero', 'tick0': -5},\n",
    "        'yaxis': {'range': [-25, 25], 'rangemode': 'tozero', 'tick0': -5},\n",
    "        'zaxis': {'range': [-25, 25], 'rangemode': 'tozero'},\n",
    "    },showlegend=False\n",
    ")\n",
    "go.Figure(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion = \"cluster\"\n",
    "level = 4\n",
    "lidar_dist = disturb_pc(lidar[:,:4], [distortion], [level], ROI, lidar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Scatter3d(x = lidar_dist[:,0],\n",
    "                     y = lidar_dist[:,1],\n",
    "                     z = lidar_dist[:,2],\n",
    "                    mode='markers', type='scatter3d',\n",
    "                    marker={\n",
    "                        'size': 1,\n",
    "                        'color': lidar_dist[:,3],\n",
    "                        'colorscale':'rainbow',\n",
    "                        'colorbar':{\"thickness\":20}\n",
    "})]\n",
    "layout = go.Layout(\n",
    "    scene={\n",
    "        'xaxis': {'range': [0, 50], 'rangemode': 'tozero', 'tick0': -5},\n",
    "        'yaxis': {'range': [-25, 25], 'rangemode': 'tozero', 'tick0': -5},\n",
    "        'zaxis': {'range': [-25, 25], 'rangemode': 'tozero'},\n",
    "    },showlegend=False\n",
    ")\n",
    "go.Figure(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcpu",
   "language": "python",
   "name": "torchcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
